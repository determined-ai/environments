ARG BASE_IMAGE
FROM ${BASE_IMAGE}

RUN rm -f /etc/apt/sources.list.d/*
ENV LANG=C.UTF-8 LC_ALL=C.UTF-8 PIP_NO_CACHE_DIR=1

# We need to create sym links for the Slurm PMI headers if we are using 
# Ubuntu 18.04 because they are not installed in a standard location.
ARG UBUNTU_VERSION
RUN mkdir -p /var/run/sshd
RUN apt-get update \
	&& DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
		autoconf \
		automake \
		autotools-dev \
		build-essential \
		ca-certificates \
		curl \
		daemontools \
		ibverbs-providers \
		libibverbs1 \
		libkrb5-dev \
		librdmacm1 \
		libssl-dev \
		libtool \
		git \
		krb5-user \
		g++ \
		cmake \
		make \
		openssh-client \
		openssh-server \
		pkg-config \
		wget \
		nfs-common \
                libnuma1 \
                libnuma-dev \
                libpmi2-0-dev \
		unattended-upgrades \
	&& unattended-upgrade \
	&& rm -rf /var/lib/apt/lists/* \
	&& rm /etc/ssh/ssh_host_ecdsa_key \
	&& rm /etc/ssh/ssh_host_ed25519_key \
	&& rm /etc/ssh/ssh_host_rsa_key \
        && if [ "$UBUNTU_VERSION" = "ubuntu18.04" ]; then ln -s /usr/include/slurm-wlm /usr/include/slurm; fi

COPY dockerfile_scripts /tmp/det_dockerfile_scripts

ENV PATH="/opt/conda/bin:${PATH}"
ENV PYTHONUNBUFFERED=1 PYTHONFAULTHANDLER=1 PYTHONHASHSEED=0
ARG PYTHON_VERSION
RUN /tmp/det_dockerfile_scripts/install_python.sh ${PYTHON_VERSION}

ARG WITH_MPI
ARG WITH_OFI
ARG UCX_INSTALL_DIR=/container/ucx
ARG OMPI_INSTALL_DIR=/container/ompi
ARG OFI_INSTALL_DIR=/container/ofi
ARG AWS_PLUGIN_INSTALL_DIR=/container/aws
ARG WITH_AWS_TRACE
ARG OMPI_WITH_CUDA=1
RUN if [ "$WITH_MPI" = "1" ]; then /tmp/det_dockerfile_scripts/ompi.sh "$UBUNTU_VERSION" "$WITH_OFI" "$OMPI_WITH_CUDA" "$WITH_AWS_TRACE"; fi
# Make sure OMPI/UCX show up in the right paths
ARG VERBS_LIB_DIR=/usr/lib/libibverbs
ARG UCX_LIB_DIR=${UCX_INSTALL_DIR}/lib:${UCX_INSTALL_DIR}/lib64
ARG UCX_PATH_DIR=${UCX_INSTALL_DIR}/bin
ARG OFI_LIB_DIR=${OFI_INSTALL_DIR}/lib:${OFI_INSTALL_DIR}/lib64
ARG OFI_PATH_DIR=${OFI_INSTALL_DIR}/bin
ARG OMPI_LIB_DIR=${OMPI_INSTALL_DIR}/lib
ARG OMPI_PATH_DIR=${OMPI_INSTALL_DIR}/bin
ARG AWS_LIB_DIR=${AWS_PLUGIN_INSTALL_DIR}/lib

#USING OFI
ENV LD_LIBRARY_PATH=${WITH_OFI:+$LD_LIBRARY_PATH:${WITH_MPI:+$VERBS_LIB_DIR:$OFI_LIB_DIR:$OMPI_LIB_DIR}}
ENV LD_LIBRARY_PATH=${WITH_OFI:+${WITH_MPI:+$AWS_LIB_DIR:$LD_LIBRARY_PATH}}
ENV PATH=${PATH}:${WITH_OFI:+$PATH:${WITH_MPI:+$OFI_PATH_DIR:$OMPI_PATH_DIR}}

#USING UCX
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH:-$LD_LIBRARY_PATH:${WITH_MPI:+$VERBS_LIB_DIR:$UCX_LIB_DIR:$OMPI_LIB_DIR}}
ENV PATH=${PATH:-$CONDA:${WITH_MPI:+$UCX_PATH_DIR:$OMPI_PATH_DIR}}

# Enable running OMPI as root
ENV OMPI_ALLOW_RUN_AS_ROOT ${WITH_MPI:+1}
ENV OMPI_ALLOW_RUN_AS_ROOT_CONFIRM ${WITH_MPI:+1}


# We uninstall these packages after installing. This ensures that we can
# successfully install these packages into containers running as non-root.
# `pip` does not uninstall dependencies, so we still have all the dependencies
# installed.
RUN python -m pip install determined && python -m pip uninstall -y determined

RUN python -m pip install -r /tmp/det_dockerfile_scripts/notebook-requirements.txt
ENV JUPYTER_CONFIG_DIR=/run/determined/jupyter/config
ENV JUPYTER_DATA_DIR=/run/determined/jupyter/data
ENV JUPYTER_RUNTIME_DIR=/run/determined/jupyter/runtime

RUN /tmp/det_dockerfile_scripts/add_det_nobody_user.sh

RUN /tmp/det_dockerfile_scripts/install_libnss_determined.sh

# Set an entrypoint that can scrape up the host libfabric.so and then 
# run the user command. This is intended to enable performant execution
# on non-IB systems that have a proprietary libfabric.
RUN mkdir -p /container/bin && \
    cp /tmp/det_dockerfile_scripts/scrape_libs.sh /container/bin
ENTRYPOINT ["/container/bin/scrape_libs.sh"]

RUN rm -r /tmp/*

